{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# irt\n",
    "\n",
    "> Some basic tooling in item response theory for analyzing the results of ML benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp irt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will use item response theory (IRT) to analyze benchmark results. \n",
    "\n",
    "A common model in IRT is the Rasch model, which described the probability of a correct response ($P(X=1)$) as a function of the ability of the person ($\\theta_n$) and the difficulty ($\\beta_i$) of the item: \n",
    "\n",
    "$$\n",
    "P(X_{ni} =1| \\theta_n, \\beta_i) = \\frac{\\exp\\{\\theta_n - \\beta_i\\}}{1 + \\exp\\{\\theta_n - \\beta_i\\}}\n",
    "$$\n",
    "\n",
    "We can make this more general by adding a discrimination parameter $\\alpha_i$: This parameter describes how well the item discriminates between models of different abilities. The probability of a correct response is then given by:\n",
    "\n",
    "$$\n",
    "P(X_{ni} =1| \\theta_n, \\beta_i, \\alpha_i) = \\frac{\\exp\\{\\alpha_i(\\theta_n - \\beta_i)\\}}{1 + \\exp\\{\\alpha_i(\\theta_n - \\beta_i)\\}}\n",
    "$$\n",
    "\n",
    "This is the 2PL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import numpy as np \n",
    "from girth import twopl_mml, rasch_mml, ability_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kevinmaikjablonka/Downloads/model_score_dict.pkl', 'rb') as f:\n",
    "    model_score_dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canary_0</th>\n",
       "      <th>description_0</th>\n",
       "      <th>keywords_0</th>\n",
       "      <th>llm_extraction_count_0</th>\n",
       "      <th>metrics_correct_classes</th>\n",
       "      <th>metrics_extra_classes</th>\n",
       "      <th>metrics_f1</th>\n",
       "      <th>metrics_hamming</th>\n",
       "      <th>metrics_incorrect_classes</th>\n",
       "      <th>metrics_missed_classes</th>\n",
       "      <th>...</th>\n",
       "      <th>is_analytical_chemistry</th>\n",
       "      <th>is_periodic_table</th>\n",
       "      <th>is_general_chemistry_exam</th>\n",
       "      <th>is_biomolecular</th>\n",
       "      <th>is_xray</th>\n",
       "      <th>is_materials_science</th>\n",
       "      <th>is_molsim</th>\n",
       "      <th>requires_calculation</th>\n",
       "      <th>is_preference</th>\n",
       "      <th>is_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>ghs pictograms</td>\n",
       "      <td>[pubchem, pictograms, safety]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Predicting the appropriate stoichiometric coef...</td>\n",
       "      <td>[stoichiometric coefficient, physical-chemistr...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Chemical mixing compatibility test</td>\n",
       "      <td>[chemicals, safety compatibility test, reactiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Diazonium Salts characteristics questions, inc...</td>\n",
       "      <td>[chemistry, molecules, diazonium salts, organi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Amines, Aromatic characteristics questions, in...</td>\n",
       "      <td>[amines, aromatic, requires-knowledge, safety,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Solid state chemistry questions related to poi...</td>\n",
       "      <td>[solid state chemistry, requires-reasoning, di...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>General questions on apatite</td>\n",
       "      <td>[apatite, substitutions in apatite, chemical f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Chemical mixing compatibility test</td>\n",
       "      <td>[chemicals, safety compatibility test, reactiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Preference for further drug development</td>\n",
       "      <td>[preference, requires-intuition]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Predicting the total number of structural isom...</td>\n",
       "      <td>[isomers, requires-reasoning, dfficulty-basic]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2854 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               canary_0  \\\n",
       "0     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "1     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "3     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "4     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "...                                                 ...   \n",
       "2849  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2850  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2851  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2852  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2853  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "\n",
       "                                          description_0  \\\n",
       "0                                        ghs pictograms   \n",
       "1     Predicting the appropriate stoichiometric coef...   \n",
       "2                    Chemical mixing compatibility test   \n",
       "3     Diazonium Salts characteristics questions, inc...   \n",
       "4     Amines, Aromatic characteristics questions, in...   \n",
       "...                                                 ...   \n",
       "2849  Solid state chemistry questions related to poi...   \n",
       "2850                       General questions on apatite   \n",
       "2851                 Chemical mixing compatibility test   \n",
       "2852            Preference for further drug development   \n",
       "2853  Predicting the total number of structural isom...   \n",
       "\n",
       "                                             keywords_0  \\\n",
       "0                         [pubchem, pictograms, safety]   \n",
       "1     [stoichiometric coefficient, physical-chemistr...   \n",
       "2     [chemicals, safety compatibility test, reactiv...   \n",
       "3     [chemistry, molecules, diazonium salts, organi...   \n",
       "4     [amines, aromatic, requires-knowledge, safety,...   \n",
       "...                                                 ...   \n",
       "2849  [solid state chemistry, requires-reasoning, di...   \n",
       "2850  [apatite, substitutions in apatite, chemical f...   \n",
       "2851  [chemicals, safety compatibility test, reactiv...   \n",
       "2852                   [preference, requires-intuition]   \n",
       "2853     [isomers, requires-reasoning, dfficulty-basic]   \n",
       "\n",
       "      llm_extraction_count_0  metrics_correct_classes  metrics_extra_classes  \\\n",
       "0                          0                      0.0                    1.0   \n",
       "1                          0                      NaN                    NaN   \n",
       "2                          0                      3.0                    3.0   \n",
       "3                          0                      1.0                    0.0   \n",
       "4                          0                      1.0                    0.0   \n",
       "...                      ...                      ...                    ...   \n",
       "2849                       0                      1.0                    0.0   \n",
       "2850                       0                      1.0                    0.0   \n",
       "2851                       0                      2.0                    3.0   \n",
       "2852                       0                      1.0                    0.0   \n",
       "2853                       0                      NaN                    NaN   \n",
       "\n",
       "      metrics_f1  metrics_hamming  metrics_incorrect_classes  \\\n",
       "0       0.000000              2.0                        1.0   \n",
       "1            NaN              NaN                        NaN   \n",
       "2       0.666667              1.0                        3.0   \n",
       "3       1.000000              0.0                        0.0   \n",
       "4       1.000000              0.0                        0.0   \n",
       "...          ...              ...                        ...   \n",
       "2849    1.000000              0.0                        0.0   \n",
       "2850    1.000000              0.0                        0.0   \n",
       "2851    0.571429              1.5                        3.0   \n",
       "2852    1.000000              0.0                        0.0   \n",
       "2853         NaN              NaN                        NaN   \n",
       "\n",
       "      metrics_missed_classes  ...  is_analytical_chemistry  is_periodic_table  \\\n",
       "0                        1.0  ...                    False              False   \n",
       "1                        NaN  ...                    False              False   \n",
       "2                        0.0  ...                    False              False   \n",
       "3                        0.0  ...                    False              False   \n",
       "4                        0.0  ...                    False              False   \n",
       "...                      ...  ...                      ...                ...   \n",
       "2849                     0.0  ...                    False              False   \n",
       "2850                     0.0  ...                    False              False   \n",
       "2851                     0.0  ...                    False              False   \n",
       "2852                     0.0  ...                    False              False   \n",
       "2853                     NaN  ...                    False              False   \n",
       "\n",
       "      is_general_chemistry_exam is_biomolecular is_xray is_materials_science  \\\n",
       "0                         False           False   False                False   \n",
       "1                         False           False   False                False   \n",
       "2                         False           False   False                False   \n",
       "3                         False           False   False                False   \n",
       "4                         False           False   False                False   \n",
       "...                         ...             ...     ...                  ...   \n",
       "2849                      False           False   False                False   \n",
       "2850                      False           False   False                 True   \n",
       "2851                      False           False   False                False   \n",
       "2852                      False           False   False                False   \n",
       "2853                      False           False   False                False   \n",
       "\n",
       "     is_molsim requires_calculation is_preference  is_name  \n",
       "0        False                  NaN         False    False  \n",
       "1        False                  NaN         False    False  \n",
       "2        False                  NaN         False    False  \n",
       "3        False                  NaN         False    False  \n",
       "4        False                  NaN         False    False  \n",
       "...        ...                  ...           ...      ...  \n",
       "2849     False                  NaN         False    False  \n",
       "2850     False                  NaN         False    False  \n",
       "2851     False                  NaN         False    False  \n",
       "2852     False                  NaN          True    False  \n",
       "2853     False                  NaN         False    False  \n",
       "\n",
       "[2854 rows x 77 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_dicts['overall']['Claude-2-Zero-T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ScoringType(Enum): \n",
    "    BINARY = 'binary'\n",
    "    PARTIAL = 'partial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a container to store meta information for each question (item). We will track some identifier and what type of scoring the question uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@dataclass\n",
    "class QuestionMetadata:\n",
    "    \"\"\"Base class for question metadata\"\"\"\n",
    "    question_id: str\n",
    "    scoring_type: ScoringType\n",
    "\n",
    "    def compute_score(self, response) -> float:\n",
    "        \"\"\"Base method for computing scores\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@dataclass\n",
    "class BinaryQuestionMetadata(QuestionMetadata):\n",
    "    \"\"\"Metadata for binary scored questions\"\"\"\n",
    "    def __init__(self, question_id: str):\n",
    "        super().__init__(question_id, ScoringType.BINARY)\n",
    "\n",
    "    def compute_score(self, row, column: str='all_correct_') -> float:\n",
    "        \"\"\"Use the all_correct column directly\"\"\"\n",
    "        return float(row[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class BenchmarkAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model_dataframes: Dict[str, pd.DataFrame] = {}\n",
    "        self.question_metadata: Dict[str, QuestionMetadata] = {}\n",
    "        self.score_matrix = None\n",
    "        self.model_ids = None\n",
    "\n",
    "    def add_model_results(self, model_id: str, results_df: pd.DataFrame):\n",
    "        \"\"\"Add a model's results DataFrame\"\"\"\n",
    "        self.model_dataframes[model_id] = results_df\n",
    "\n",
    "    def add_question_metadata(self, metadata: QuestionMetadata):\n",
    "        \"\"\"Add metadata for a question\"\"\"\n",
    "        self.question_metadata[metadata.question_id] = metadata\n",
    "\n",
    "    def compute_score_matrix(self) -> np.ndarray:\n",
    "        \"\"\"Compute score matrix using metadata-specific scoring\"\"\"\n",
    "        if not self.model_dataframes or not self.question_metadata:\n",
    "            raise ValueError(\"Need both model results and question metadata\")\n",
    "\n",
    "        self.model_ids = list(self.model_dataframes.keys())\n",
    "        question_ids = list(self.question_metadata.keys())\n",
    "\n",
    "        # Initialize score matrix\n",
    "        self.score_matrix = np.full(\n",
    "            (len(self.model_ids), len(question_ids)), \n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "        # Compute scores\n",
    "        for model_idx, model_id in enumerate(self.model_ids):\n",
    "            df = self.model_dataframes[model_id]\n",
    "            for q_idx, q_id in enumerate(question_ids):\n",
    "                if q_id not in df.index:\n",
    "                    continue\n",
    "\n",
    "                metadata = self.question_metadata[q_id]\n",
    "                row = df.loc[q_id]\n",
    "\n",
    "                self.score_matrix[model_idx, q_idx] = metadata.compute_score(row)\n",
    "\n",
    "\n",
    "        return self.score_matrix\n",
    "\n",
    "    def fit_irt(self, model='2pl') -> Dict[str, pd.DataFrame]:\n",
    "        if self.score_matrix is None:\n",
    "            self.compute_score_matrix()\n",
    "\n",
    "        binary_matrix = (self.score_matrix >= 0.5).astype(int).T #  needs to be [n_items, n_participants]\n",
    "        \n",
    "        if model == '2pl':\n",
    "            # options = {\n",
    "            # 'max_iteration': 200,\n",
    "            # 'quadrature_n': 61,  # More quadrature points for better precision\n",
    "            # 'quadrature_bounds': (-6, 6),  # Default bounds\n",
    "            # 'estimate_distribution': True  # Allow distribution estimation\n",
    "            # }\n",
    "\n",
    "            results = twopl_mml(binary_matrix)\n",
    "            difficulties = results['Difficulty']\n",
    "            discriminations = results['Discrimination']\n",
    "        else:  # rasch\n",
    "            results = rasch_mml(binary_matrix)\n",
    "            difficulties = results['Difficulty']\n",
    "            discriminations = np.ones_like(difficulties) \n",
    "        \n",
    "        abilities = ability_mle(\n",
    "            binary_matrix,  \n",
    "            difficulties,\n",
    "            discriminations,\n",
    "            no_estimate=np.nan  \n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'difficulties': difficulties,\n",
    "            'discriminations': discriminations,\n",
    "            'abilities': abilities, \n",
    "            'binary_matrix': binary_matrix\n",
    "        }\n",
    "\n",
    "\n",
    "    def analyze_extreme_items(difficulties, discriminations, question_ids, threshold=0.95):\n",
    "        \"\"\"Identify items with extreme parameters\"\"\"\n",
    "        extreme_items = pd.DataFrame({\n",
    "            'question_id': question_ids,\n",
    "            'difficulty': difficulties,\n",
    "            'discrimination': discriminations\n",
    "        })\n",
    "\n",
    "        # Find items with extreme values\n",
    "        extreme_items['is_extreme'] = (\n",
    "            (discriminations > threshold * 5.0) |  # High discrimination\n",
    "            (difficulties > threshold * 6.0) |     # Very difficult\n",
    "            (difficulties < -4.0)                  # Very easy\n",
    "        )\n",
    "\n",
    "        return extreme_items[extreme_items['is_extreme']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's the class with some of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = BenchmarkAnalyzer()\n",
    "\n",
    "for model_id, df in model_score_dicts['overall'].items():\n",
    "    analyzer.add_model_results(model_id, df)\n",
    "\n",
    "\n",
    "# for now, let's just add the binary questions\n",
    "for i, row in model_score_dicts['overall']['Claude-2-Zero-T'].iterrows():\n",
    "    if row['metrics_hamming']:\n",
    "        analyzer.add_question_metadata(BinaryQuestionMetadata(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/irt/lib/python3.11/site-packages/girth/unidimensional/dichotomous/rasch_mml.py:108: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log(otpt).dot(counts)\n"
     ]
    }
   ],
   "source": [
    "results = analyzer.fit_irt(model='rasch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'difficulties': array([ 2.17320999,  0.22051166,  5.99993935, ..., -1.78526175,\n",
       "         1.46119429, -0.22054479]),\n",
       " 'discriminations': array([1., 1., 1., ..., 1., 1., 1.]),\n",
       " 'abilities': array([ 0.92062274,  0.70085661,  0.43172056, -0.33257593,  0.18210808,\n",
       "         0.97653286,  0.26776643,  0.95411399,  0.46383346,  0.73349057,\n",
       "        -1.47287807,  0.30697452, -1.099009  , -4.0792575 ,  0.28559071,\n",
       "         0.27133169,  1.18214098, -0.5245331 ,  0.32122829, -0.2613409 ,\n",
       "         0.20711413, -3.02995173]),\n",
       " 'binary_matrix': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 1, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mistral-Large-2': 0.9206227382517711,\n",
       " 'Llama-3.1-70B-Instruct': 0.7008566079326864,\n",
       " 'Claude-3.5 (Sonnet)': 0.43172056318578506,\n",
       " 'Mistral-8x7b-Instruct': -0.33257592815906706,\n",
       " 'Command-R+': 0.18210807975250953,\n",
       " 'Llama-3.1-405B-Instruct': 0.976532863706392,\n",
       " 'Llama-3.1-8B-Instruct': 0.26776643434833536,\n",
       " 'GPT-4o': 0.954113987494647,\n",
       " 'Llama-3-70B-Instruct': 0.46383345663883774,\n",
       " 'PaperQA2': 0.7334905687001801,\n",
       " 'Gemma-1.1-7B-it': -1.472878071397841,\n",
       " 'Gemma-2-9B-it': 0.30697451785597074,\n",
       " 'Llama-2-70B Chat': -1.0990090007354893,\n",
       " 'Galatica-120b': -4.079257501775907,\n",
       " 'Llama-3-8B-Instruct': 0.2855907076410609,\n",
       " 'Gemini-Pro': 0.2713316860822229,\n",
       " 'o1': 1.1821409799492104,\n",
       " 'GPT-4': -0.5245330961997795,\n",
       " 'Phi-3-Medium-4k-Instruct': 0.32122828793906116,\n",
       " 'Claude-3 (Opus)': -0.2613409044033738,\n",
       " 'GPT-3.5 Turbo Zero-T': 0.2071141267589506,\n",
       " 'Claude-2-Zero-T': -3.0299517299011396}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(analyzer.model_ids, results['abilities']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be quite different from a naive ranking based on taking the mean of the scores.\n",
    "Let's perform some more detailed analysis what causes the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22,)\n",
      "                          irt_ability  avg_score  irt_rank  avg_rank\n",
      "model_id                                                            \n",
      "Mistral-Large-2              0.920623   0.545849       4.0       4.0\n",
      "Llama-3.1-70B-Instruct       0.700857   0.508674       6.0       6.0\n",
      "Claude-3.5 (Sonnet)          0.431721   0.462206       8.0       8.0\n",
      "Mistral-8x7b-Instruct       -0.332576   0.331475      17.0      17.0\n",
      "Command-R+                   0.182108   0.418835      15.0      15.0\n",
      "Llama-3.1-405B-Instruct      0.976533   0.555143       2.0       2.0\n",
      "Llama-3.1-8B-Instruct        0.267766   0.433705      13.0      13.0\n",
      "GPT-4o                       0.954114   0.551425       3.0       3.0\n",
      "Llama-3-70B-Instruct         0.463833   0.467782       7.0       7.0\n",
      "PaperQA2                     0.733491   0.514250       5.0       5.0\n",
      "Gemma-1.1-7B-it             -1.472878   0.169765      20.0      20.0\n",
      "Gemma-2-9B-it                0.306975   0.440520      10.0      10.0\n",
      "Llama-2-70B Chat            -1.099009   0.216233      19.0      19.0\n",
      "Galatica-120b               -4.079258   0.019827      22.0      22.0\n",
      "Llama-3-8B-Instruct          0.285591   0.436803      11.0      11.0\n",
      "Gemini-Pro                   0.271332   0.434325      12.0      12.0\n",
      "o1                           1.182141   0.588600       1.0       1.0\n",
      "GPT-4                       -0.524533   0.300496      18.0      18.0\n",
      "Phi-3-Medium-4k-Instruct     0.321228   0.442999       9.0       9.0\n",
      "Claude-3 (Opus)             -0.261341   0.343247      16.0      16.0\n",
      "GPT-3.5 Turbo Zero-T         0.207114   0.423172      14.0      14.0\n",
      "Claude-2-Zero-T             -3.029952   0.050805      21.0      21.0\n",
      "\n",
      "Models with largest ranking differences:\n",
      "Empty DataFrame\n",
      "Columns: [irt_ability, avg_score, irt_rank, avg_rank, rank_diff]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def analyze_influential_questions(binary_matrix, abilities, difficulties, discriminations, model_ids, question_ids):\n",
    "    \"\"\"Analyze which questions cause the biggest differences between IRT and average scoring\"\"\"\n",
    "\n",
    "    # Get both scoring methods\n",
    "    avg_scores = np.mean(binary_matrix.T, axis=1)\n",
    "    print(avg_scores.shape)\n",
    "\n",
    "    # Create base comparison DataFrame\n",
    "    model_comparison = pd.DataFrame({\n",
    "        'model_id': model_ids,\n",
    "        'irt_ability': abilities,\n",
    "        'avg_score': avg_scores,\n",
    "        'irt_rank': pd.Series(abilities).rank(ascending=False),\n",
    "        'avg_rank': pd.Series(avg_scores).rank(ascending=False)\n",
    "    }).set_index('model_id')\n",
    "    print(model_comparison)\n",
    "\n",
    "    # Find models with large ranking differences\n",
    "    model_comparison['rank_diff'] = model_comparison['avg_rank'] - model_comparison['irt_rank']\n",
    "    interesting_models = model_comparison[abs(model_comparison['rank_diff']) > 2]\n",
    "\n",
    "    # Analyze question characteristics for these models\n",
    "    question_analysis = pd.DataFrame({\n",
    "        'question_id': question_ids,\n",
    "        'difficulty': difficulties,\n",
    "        'discrimination': discriminations,\n",
    "        'avg_success_rate': np.mean(binary_matrix.T, axis=0)\n",
    "    })\n",
    "\n",
    "    # For each interesting model, analyze its response pattern\n",
    "    for model_id in interesting_models.index:\n",
    "        model_idx = model_ids.index(model_id)\n",
    "        responses = binary_matrix[model_idx]\n",
    "\n",
    "        # Calculate contribution to IRT score\n",
    "        # Higher contribution when succeeding on difficult/discriminating items\n",
    "        question_analysis[f'{model_id}_contribution'] = (\n",
    "            responses * discriminations * (difficulties - abilities[model_idx])\n",
    "        )\n",
    "\n",
    "        # Add raw response\n",
    "        question_analysis[f'{model_id}_response'] = responses\n",
    "\n",
    "    # Find most influential questions\n",
    "    influential_questions = question_analysis[\n",
    "        (question_analysis['discrimination'] > np.percentile(discriminations, 75)) |\n",
    "        (abs(question_analysis['difficulty']) > 2)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        'model_differences': interesting_models,\n",
    "        'influential_questions': influential_questions.sort_values('discrimination', ascending=False)\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "influential_analysis_results = analyze_influential_questions(\n",
    "    results['binary_matrix'],\n",
    "    results['abilities'], \n",
    "    results['difficulties'], \n",
    "    results['discriminations'], \n",
    "    analyzer.model_ids, \n",
    "    list(analyzer.question_metadata.keys())\n",
    ")\n",
    "\n",
    "print(\"\\nModels with largest ranking differences:\")\n",
    "print(influential_analysis_results['model_differences'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most influential questions:\n",
      "     question_id  difficulty  discrimination  avg_success_rate\n",
      "0              0    2.173210             1.0          0.136364\n",
      "821         1450    2.173210             1.0          0.136364\n",
      "892         1585    5.999939             1.0          0.000000\n",
      "884         1566    2.679903             1.0          0.090909\n",
      "862         1527   -3.477644             1.0          0.954545\n",
      "849         1498    2.173210             1.0          0.136364\n",
      "848         1497    2.173210             1.0          0.136364\n",
      "835         1471    3.477478             1.0          0.045455\n",
      "828         1462    5.999939             1.0          0.000000\n",
      "824         1454    2.173210             1.0          0.136364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nMost influential questions:\")\n",
    "print(influential_analysis_results['influential_questions'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "canary_0                   BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...\n",
       "description_0                                    Distribution of antibiotics\n",
       "keywords_0                 [antibiotic, distribution, pharmacokinetics, r...\n",
       "llm_extraction_count_0                                                     0\n",
       "metrics_correct_classes                                                  1.0\n",
       "                                                 ...                        \n",
       "is_materials_science                                                   False\n",
       "is_molsim                                                              False\n",
       "requires_calculation                                                     NaN\n",
       "is_preference                                                          False\n",
       "is_name                                                                False\n",
       "Name: 1879, Length: 77, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_dicts['overall']['GPT-4'].iloc[1879]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 330x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "influential_analysis_results['influential_questions']['difficulty'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>discrimination</th>\n",
       "      <th>avg_success_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1527</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>1590</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1595</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1778</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1775</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1596</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>977</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>946</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2563</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>2386</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1900</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>2801</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>2658</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>2631</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>2374</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>2113</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>2282</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>366</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>186</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>497</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>694</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>769</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>664</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>528</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>523</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>609</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id  difficulty  discrimination  avg_success_rate\n",
       "862          1527   -3.477644             1.0          0.954545\n",
       "894          1590   -2.173275             1.0          0.863636\n",
       "898          1595   -2.173275             1.0          0.863636\n",
       "998          1778   -2.173275             1.0          0.863636\n",
       "996          1775   -2.679993             1.0          0.909091\n",
       "899          1596   -2.173275             1.0          0.863636\n",
       "563           977   -2.173275             1.0          0.863636\n",
       "544           946   -2.173275             1.0          0.863636\n",
       "1448         2563   -3.477644             1.0          0.954545\n",
       "1349         2386   -2.679993             1.0          0.909091\n",
       "1069         1900   -2.173275             1.0          0.863636\n",
       "1582         2801   -3.477644             1.0          0.954545\n",
       "1492         2658   -2.679993             1.0          0.909091\n",
       "1481         2631   -2.679993             1.0          0.909091\n",
       "1343         2374   -2.679993             1.0          0.909091\n",
       "1192         2113   -2.679993             1.0          0.909091\n",
       "1290         2282   -2.173275             1.0          0.863636\n",
       "207           366   -2.173275             1.0          0.863636\n",
       "16             25   -2.679993             1.0          0.909091\n",
       "106           186   -3.477644             1.0          0.954545\n",
       "278           497   -2.173275             1.0          0.863636\n",
       "400           694   -2.679993             1.0          0.909091\n",
       "439           769   -2.679993             1.0          0.909091\n",
       "382           664   -2.173275             1.0          0.863636\n",
       "296           528   -3.477644             1.0          0.954545\n",
       "291           523   -2.173275             1.0          0.863636\n",
       "343           609   -2.679993             1.0          0.909091"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influential_analysis_results['influential_questions'][influential_analysis_results['influential_questions']['difficulty']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following is a question about chemistry.\\n\\nQuestion: The reaction of sulfur dioxide with calcium carbonate and oxygen is 2SO2 + 2CaCO3 + O2 -> xCaSO4 + 2CO2. What is x?\\n\\nYou MUST include the final answer within the following tags: [ANSWER] and [/ANSWER].\\nFor example, '[ANSWER]<answer>[/ANSWER]', where <answer> is only one number. Always answer in exactly this format, with ONE NUMBER between the two tags, even if you are unsure. Use dots as decimal separator. We require this because we use automatic parsing.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_dicts['overall']['GPT-4'].iloc[1590]['prompt_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can make it Bayesian with `pymc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "\n",
    "def fit_2pl_pymc(response_matrix, n_samples=2000, tune=2000):\n",
    "    n_participants, n_items = response_matrix.shape\n",
    "\n",
    "    with pm.Model() as irt_2pl:\n",
    "        # 1. Standardize input data if not already done\n",
    "        # response_matrix = (response_matrix - np.mean(response_matrix)) / np.std(response_matrix)\n",
    "\n",
    "        # 2. Abilities with stronger regularization\n",
    "        abilities = pm.Normal('abilities', \n",
    "                            mu=0, \n",
    "                            sigma=0.5,  # Tighter prior\n",
    "                            shape=n_participants)\n",
    "\n",
    "        # 3. Simpler discrimination parameterization\n",
    "        # Constrain to reasonable range [0.5, 2.5]\n",
    "        discriminations = pm.TruncatedNormal('discriminations',\n",
    "                                           mu=1.0,\n",
    "                                           sigma=0.3,\n",
    "                                           lower=0.5,\n",
    "                                           upper=2.5,\n",
    "                                           shape=n_items)\n",
    "\n",
    "        # 4. Difficulties with tighter bounds\n",
    "        difficulties = pm.TruncatedNormal('difficulties',\n",
    "                                        mu=0,\n",
    "                                        sigma=0.5,\n",
    "                                        lower=-2,\n",
    "                                        upper=2,\n",
    "                                        shape=n_items)\n",
    "\n",
    "        # 5. More stable computation with scaling\n",
    "        scaled_abilities = abilities[:, None] / 2.0  # Scale down\n",
    "        scaled_difficulties = difficulties[None, :] / 2.0\n",
    "        scaled_disc = discriminations[None, :] / 2.0\n",
    "\n",
    "        # Compute logit with scaled parameters\n",
    "        logit_p = scaled_disc * (scaled_abilities - scaled_difficulties)\n",
    "\n",
    "        # 6. Likelihood\n",
    "        responses = pm.Bernoulli('responses',\n",
    "                                logit_p=logit_p,\n",
    "                                observed=response_matrix)\n",
    "\n",
    "        # 7. Improved sampling settings\n",
    "        trace = pm.sample(n_samples,\n",
    "                         tune=tune,\n",
    "                         chains=4,\n",
    "                         target_accept=0.99,\n",
    "                         init='jitter+adapt_diag',  # Different initializer\n",
    "                         return_inferencedata=True,\n",
    "                         cores=1)  # Single core for better stability\n",
    "\n",
    "    return trace\n",
    "\n",
    "# Modern diagnostics using ArviZ\n",
    "def check_model_diagnostics(trace):\n",
    "    \"\"\"Comprehensive model diagnostics\"\"\"\n",
    "    diagnostics = {\n",
    "        'r_hat': az.rhat(trace),\n",
    "        'ess': az.ess(trace),\n",
    "        'mcse': az.mcse(trace),\n",
    "        'divergences': az.summary(trace)['diverging'].sum()\n",
    "    }\n",
    "\n",
    "    # Check for convergence issues\n",
    "    has_issues = (\n",
    "        (diagnostics['r_hat'] > 1.01).any() or\n",
    "        (diagnostics['ess'] < 400).any() or\n",
    "        diagnostics['divergences'] > 0\n",
    "    )\n",
    "\n",
    "    if has_issues:\n",
    "        print(\"Warning: Potential convergence issues detected\")\n",
    "\n",
    "    return diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (4 chains in 1 job)\n",
      "NUTS: [abilities, discriminations, difficulties]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcbd4f9be2240c4a5686ee7e093bcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e61f50ecdc40ed906a9e4d2378821d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7434e296861649a69edaa21448ba2d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3e821b76654316a0a901cf3bb26f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 2_000 draw iterations (8_000 + 8_000 draws total) took 1790 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    trace = fit_2pl_pymc(results['binary_matrix'].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic summary statistics\n",
    "summary = az.summary(trace, var_names=['abilities', 'discriminations', 'difficulties'])\n",
    "\n",
    "# 2. Extract posterior means directly\n",
    "abilities_mean = trace.posterior['abilities'].mean(dim=['chain', 'draw']).values\n",
    "discriminations_mean = trace.posterior['discriminations'].mean(dim=['chain', 'draw']).values\n",
    "difficulties_mean = trace.posterior['difficulties'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# 3. Get full posterior distributions\n",
    "abilities_dist = trace.posterior['abilities'].values\n",
    "discriminations_dist = trace.posterior['discriminations'].values\n",
    "difficulties_dist = trace.posterior['difficulties'].values\n",
    "\n",
    "# 4. Get credible intervals\n",
    "summary = az.summary(trace, var_names=['abilities', 'discriminations', 'difficulties'],\n",
    "                    hdi_prob=0.95)  # 95% credible intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abilities[0]',\n",
       " 'abilities[1]',\n",
       " 'abilities[2]',\n",
       " 'abilities[3]',\n",
       " 'abilities[4]',\n",
       " 'abilities[5]',\n",
       " 'abilities[6]',\n",
       " 'abilities[7]',\n",
       " 'abilities[8]',\n",
       " 'abilities[9]',\n",
       " 'abilities[10]',\n",
       " 'abilities[11]',\n",
       " 'abilities[12]',\n",
       " 'abilities[13]',\n",
       " 'abilities[14]',\n",
       " 'abilities[15]',\n",
       " 'abilities[16]',\n",
       " 'abilities[17]',\n",
       " 'abilities[18]',\n",
       " 'abilities[19]',\n",
       " 'abilities[20]',\n",
       " 'abilities[21]',\n",
       " 'discriminations[0]',\n",
       " 'discriminations[1]',\n",
       " 'discriminations[2]',\n",
       " 'discriminations[3]',\n",
       " 'discriminations[4]',\n",
       " 'discriminations[5]',\n",
       " 'discriminations[6]',\n",
       " 'discriminations[7]',\n",
       " 'discriminations[8]',\n",
       " 'discriminations[9]',\n",
       " 'discriminations[10]',\n",
       " 'discriminations[11]',\n",
       " 'discriminations[12]',\n",
       " 'discriminations[13]',\n",
       " 'discriminations[14]',\n",
       " 'discriminations[15]',\n",
       " 'discriminations[16]',\n",
       " 'discriminations[17]',\n",
       " 'discriminations[18]',\n",
       " 'discriminations[19]',\n",
       " 'discriminations[20]',\n",
       " 'discriminations[21]',\n",
       " 'discriminations[22]',\n",
       " 'discriminations[23]',\n",
       " 'discriminations[24]',\n",
       " 'discriminations[25]',\n",
       " 'discriminations[26]',\n",
       " 'discriminations[27]',\n",
       " 'discriminations[28]',\n",
       " 'discriminations[29]',\n",
       " 'discriminations[30]',\n",
       " 'discriminations[31]',\n",
       " 'discriminations[32]',\n",
       " 'discriminations[33]',\n",
       " 'discriminations[34]',\n",
       " 'discriminations[35]',\n",
       " 'discriminations[36]',\n",
       " 'discriminations[37]',\n",
       " 'discriminations[38]',\n",
       " 'discriminations[39]',\n",
       " 'discriminations[40]',\n",
       " 'discriminations[41]',\n",
       " 'discriminations[42]',\n",
       " 'discriminations[43]',\n",
       " 'discriminations[44]',\n",
       " 'discriminations[45]',\n",
       " 'discriminations[46]',\n",
       " 'discriminations[47]',\n",
       " 'discriminations[48]',\n",
       " 'discriminations[49]',\n",
       " 'discriminations[50]',\n",
       " 'discriminations[51]',\n",
       " 'discriminations[52]',\n",
       " 'discriminations[53]',\n",
       " 'discriminations[54]',\n",
       " 'discriminations[55]',\n",
       " 'discriminations[56]',\n",
       " 'discriminations[57]',\n",
       " 'discriminations[58]',\n",
       " 'discriminations[59]',\n",
       " 'discriminations[60]',\n",
       " 'discriminations[61]',\n",
       " 'discriminations[62]',\n",
       " 'discriminations[63]',\n",
       " 'discriminations[64]',\n",
       " 'discriminations[65]',\n",
       " 'discriminations[66]',\n",
       " 'discriminations[67]',\n",
       " 'discriminations[68]',\n",
       " 'discriminations[69]',\n",
       " 'discriminations[70]',\n",
       " 'discriminations[71]',\n",
       " 'discriminations[72]',\n",
       " 'discriminations[73]',\n",
       " 'discriminations[74]',\n",
       " 'discriminations[75]',\n",
       " 'discriminations[76]',\n",
       " 'discriminations[77]',\n",
       " 'discriminations[78]',\n",
       " 'discriminations[79]',\n",
       " 'discriminations[80]',\n",
       " 'discriminations[81]',\n",
       " 'discriminations[82]',\n",
       " 'discriminations[83]',\n",
       " 'discriminations[84]',\n",
       " 'discriminations[85]',\n",
       " 'discriminations[86]',\n",
       " 'discriminations[87]',\n",
       " 'discriminations[88]',\n",
       " 'discriminations[89]',\n",
       " 'discriminations[90]',\n",
       " 'discriminations[91]',\n",
       " 'discriminations[92]',\n",
       " 'discriminations[93]',\n",
       " 'discriminations[94]',\n",
       " 'discriminations[95]',\n",
       " 'discriminations[96]',\n",
       " 'discriminations[97]',\n",
       " 'discriminations[98]',\n",
       " 'discriminations[99]',\n",
       " 'discriminations[100]',\n",
       " 'discriminations[101]',\n",
       " 'discriminations[102]',\n",
       " 'discriminations[103]',\n",
       " 'discriminations[104]',\n",
       " 'discriminations[105]',\n",
       " 'discriminations[106]',\n",
       " 'discriminations[107]',\n",
       " 'discriminations[108]',\n",
       " 'discriminations[109]',\n",
       " 'discriminations[110]',\n",
       " 'discriminations[111]',\n",
       " 'discriminations[112]',\n",
       " 'discriminations[113]',\n",
       " 'discriminations[114]',\n",
       " 'discriminations[115]',\n",
       " 'discriminations[116]',\n",
       " 'discriminations[117]',\n",
       " 'discriminations[118]',\n",
       " 'discriminations[119]',\n",
       " 'discriminations[120]',\n",
       " 'discriminations[121]',\n",
       " 'discriminations[122]',\n",
       " 'discriminations[123]',\n",
       " 'discriminations[124]',\n",
       " 'discriminations[125]',\n",
       " 'discriminations[126]',\n",
       " 'discriminations[127]',\n",
       " 'discriminations[128]',\n",
       " 'discriminations[129]',\n",
       " 'discriminations[130]',\n",
       " 'discriminations[131]',\n",
       " 'discriminations[132]',\n",
       " 'discriminations[133]',\n",
       " 'discriminations[134]',\n",
       " 'discriminations[135]',\n",
       " 'discriminations[136]',\n",
       " 'discriminations[137]',\n",
       " 'discriminations[138]',\n",
       " 'discriminations[139]',\n",
       " 'discriminations[140]',\n",
       " 'discriminations[141]',\n",
       " 'discriminations[142]',\n",
       " 'discriminations[143]',\n",
       " 'discriminations[144]',\n",
       " 'discriminations[145]',\n",
       " 'discriminations[146]',\n",
       " 'discriminations[147]',\n",
       " 'discriminations[148]',\n",
       " 'discriminations[149]',\n",
       " 'discriminations[150]',\n",
       " 'discriminations[151]',\n",
       " 'discriminations[152]',\n",
       " 'discriminations[153]',\n",
       " 'discriminations[154]',\n",
       " 'discriminations[155]',\n",
       " 'discriminations[156]',\n",
       " 'discriminations[157]',\n",
       " 'discriminations[158]',\n",
       " 'discriminations[159]',\n",
       " 'discriminations[160]',\n",
       " 'discriminations[161]',\n",
       " 'discriminations[162]',\n",
       " 'discriminations[163]',\n",
       " 'discriminations[164]',\n",
       " 'discriminations[165]',\n",
       " 'discriminations[166]',\n",
       " 'discriminations[167]',\n",
       " 'discriminations[168]',\n",
       " 'discriminations[169]',\n",
       " 'discriminations[170]',\n",
       " 'discriminations[171]',\n",
       " 'discriminations[172]',\n",
       " 'discriminations[173]',\n",
       " 'discriminations[174]',\n",
       " 'discriminations[175]',\n",
       " 'discriminations[176]',\n",
       " 'discriminations[177]',\n",
       " 'discriminations[178]',\n",
       " 'discriminations[179]',\n",
       " 'discriminations[180]',\n",
       " 'discriminations[181]',\n",
       " 'discriminations[182]',\n",
       " 'discriminations[183]',\n",
       " 'discriminations[184]',\n",
       " 'discriminations[185]',\n",
       " 'discriminations[186]',\n",
       " 'discriminations[187]',\n",
       " 'discriminations[188]',\n",
       " 'discriminations[189]',\n",
       " 'discriminations[190]',\n",
       " 'discriminations[191]',\n",
       " 'discriminations[192]',\n",
       " 'discriminations[193]',\n",
       " 'discriminations[194]',\n",
       " 'discriminations[195]',\n",
       " 'discriminations[196]',\n",
       " 'discriminations[197]',\n",
       " 'discriminations[198]',\n",
       " 'discriminations[199]',\n",
       " 'discriminations[200]',\n",
       " 'discriminations[201]',\n",
       " 'discriminations[202]',\n",
       " 'discriminations[203]',\n",
       " 'discriminations[204]',\n",
       " 'discriminations[205]',\n",
       " 'discriminations[206]',\n",
       " 'discriminations[207]',\n",
       " 'discriminations[208]',\n",
       " 'discriminations[209]',\n",
       " 'discriminations[210]',\n",
       " 'discriminations[211]',\n",
       " 'discriminations[212]',\n",
       " 'discriminations[213]',\n",
       " 'discriminations[214]',\n",
       " 'discriminations[215]',\n",
       " 'discriminations[216]',\n",
       " 'discriminations[217]',\n",
       " 'discriminations[218]',\n",
       " 'discriminations[219]',\n",
       " 'discriminations[220]',\n",
       " 'discriminations[221]',\n",
       " 'discriminations[222]',\n",
       " 'discriminations[223]',\n",
       " 'discriminations[224]',\n",
       " 'discriminations[225]',\n",
       " 'discriminations[226]',\n",
       " 'discriminations[227]',\n",
       " 'discriminations[228]',\n",
       " 'discriminations[229]',\n",
       " 'discriminations[230]',\n",
       " 'discriminations[231]',\n",
       " 'discriminations[232]',\n",
       " 'discriminations[233]',\n",
       " 'discriminations[234]',\n",
       " 'discriminations[235]',\n",
       " 'discriminations[236]',\n",
       " 'discriminations[237]',\n",
       " 'discriminations[238]',\n",
       " 'discriminations[239]',\n",
       " 'discriminations[240]',\n",
       " 'discriminations[241]',\n",
       " 'discriminations[242]',\n",
       " 'discriminations[243]',\n",
       " 'discriminations[244]',\n",
       " 'discriminations[245]',\n",
       " 'discriminations[246]',\n",
       " 'discriminations[247]',\n",
       " 'discriminations[248]',\n",
       " 'discriminations[249]',\n",
       " 'discriminations[250]',\n",
       " 'discriminations[251]',\n",
       " 'discriminations[252]',\n",
       " 'discriminations[253]',\n",
       " 'discriminations[254]',\n",
       " 'discriminations[255]',\n",
       " 'discriminations[256]',\n",
       " 'discriminations[257]',\n",
       " 'discriminations[258]',\n",
       " 'discriminations[259]',\n",
       " 'discriminations[260]',\n",
       " 'discriminations[261]',\n",
       " 'discriminations[262]',\n",
       " 'discriminations[263]',\n",
       " 'discriminations[264]',\n",
       " 'discriminations[265]',\n",
       " 'discriminations[266]',\n",
       " 'discriminations[267]',\n",
       " 'discriminations[268]',\n",
       " 'discriminations[269]',\n",
       " 'discriminations[270]',\n",
       " 'discriminations[271]',\n",
       " 'discriminations[272]',\n",
       " 'discriminations[273]',\n",
       " 'discriminations[274]',\n",
       " 'discriminations[275]',\n",
       " 'discriminations[276]',\n",
       " 'discriminations[277]',\n",
       " 'discriminations[278]',\n",
       " 'discriminations[279]',\n",
       " 'discriminations[280]',\n",
       " 'discriminations[281]',\n",
       " 'discriminations[282]',\n",
       " 'discriminations[283]',\n",
       " 'discriminations[284]',\n",
       " 'discriminations[285]',\n",
       " 'discriminations[286]',\n",
       " 'discriminations[287]',\n",
       " 'discriminations[288]',\n",
       " 'discriminations[289]',\n",
       " 'discriminations[290]',\n",
       " 'discriminations[291]',\n",
       " 'discriminations[292]',\n",
       " 'discriminations[293]',\n",
       " 'discriminations[294]',\n",
       " 'discriminations[295]',\n",
       " 'discriminations[296]',\n",
       " 'discriminations[297]',\n",
       " 'discriminations[298]',\n",
       " 'discriminations[299]',\n",
       " 'discriminations[300]',\n",
       " 'discriminations[301]',\n",
       " 'discriminations[302]',\n",
       " 'discriminations[303]',\n",
       " 'discriminations[304]',\n",
       " 'discriminations[305]',\n",
       " 'discriminations[306]',\n",
       " 'discriminations[307]',\n",
       " 'discriminations[308]',\n",
       " 'discriminations[309]',\n",
       " 'discriminations[310]',\n",
       " 'discriminations[311]',\n",
       " 'discriminations[312]',\n",
       " 'discriminations[313]',\n",
       " 'discriminations[314]',\n",
       " 'discriminations[315]',\n",
       " 'discriminations[316]',\n",
       " 'discriminations[317]',\n",
       " 'discriminations[318]',\n",
       " 'discriminations[319]',\n",
       " 'discriminations[320]',\n",
       " 'discriminations[321]',\n",
       " 'discriminations[322]',\n",
       " 'discriminations[323]',\n",
       " 'discriminations[324]',\n",
       " 'discriminations[325]',\n",
       " 'discriminations[326]',\n",
       " 'discriminations[327]',\n",
       " 'discriminations[328]',\n",
       " 'discriminations[329]',\n",
       " 'discriminations[330]',\n",
       " 'discriminations[331]',\n",
       " 'discriminations[332]',\n",
       " 'discriminations[333]',\n",
       " 'discriminations[334]',\n",
       " 'discriminations[335]',\n",
       " 'discriminations[336]',\n",
       " 'discriminations[337]',\n",
       " 'discriminations[338]',\n",
       " 'discriminations[339]',\n",
       " 'discriminations[340]',\n",
       " 'discriminations[341]',\n",
       " 'discriminations[342]',\n",
       " 'discriminations[343]',\n",
       " 'discriminations[344]',\n",
       " 'discriminations[345]',\n",
       " 'discriminations[346]',\n",
       " 'discriminations[347]',\n",
       " 'discriminations[348]',\n",
       " 'discriminations[349]',\n",
       " 'discriminations[350]',\n",
       " 'discriminations[351]',\n",
       " 'discriminations[352]',\n",
       " 'discriminations[353]',\n",
       " 'discriminations[354]',\n",
       " 'discriminations[355]',\n",
       " 'discriminations[356]',\n",
       " 'discriminations[357]',\n",
       " 'discriminations[358]',\n",
       " 'discriminations[359]',\n",
       " 'discriminations[360]',\n",
       " 'discriminations[361]',\n",
       " 'discriminations[362]',\n",
       " 'discriminations[363]',\n",
       " 'discriminations[364]',\n",
       " 'discriminations[365]',\n",
       " 'discriminations[366]',\n",
       " 'discriminations[367]',\n",
       " 'discriminations[368]',\n",
       " 'discriminations[369]',\n",
       " 'discriminations[370]',\n",
       " 'discriminations[371]',\n",
       " 'discriminations[372]',\n",
       " 'discriminations[373]',\n",
       " 'discriminations[374]',\n",
       " 'discriminations[375]',\n",
       " 'discriminations[376]',\n",
       " 'discriminations[377]',\n",
       " 'discriminations[378]',\n",
       " 'discriminations[379]',\n",
       " 'discriminations[380]',\n",
       " 'discriminations[381]',\n",
       " 'discriminations[382]',\n",
       " 'discriminations[383]',\n",
       " 'discriminations[384]',\n",
       " 'discriminations[385]',\n",
       " 'discriminations[386]',\n",
       " 'discriminations[387]',\n",
       " 'discriminations[388]',\n",
       " 'discriminations[389]',\n",
       " 'discriminations[390]',\n",
       " 'discriminations[391]',\n",
       " 'discriminations[392]',\n",
       " 'discriminations[393]',\n",
       " 'discriminations[394]',\n",
       " 'discriminations[395]',\n",
       " 'discriminations[396]',\n",
       " 'discriminations[397]',\n",
       " 'discriminations[398]',\n",
       " 'discriminations[399]',\n",
       " 'discriminations[400]',\n",
       " 'discriminations[401]',\n",
       " 'discriminations[402]',\n",
       " 'discriminations[403]',\n",
       " 'discriminations[404]',\n",
       " 'discriminations[405]',\n",
       " 'discriminations[406]',\n",
       " 'discriminations[407]',\n",
       " 'discriminations[408]',\n",
       " 'discriminations[409]',\n",
       " 'discriminations[410]',\n",
       " 'discriminations[411]',\n",
       " 'discriminations[412]',\n",
       " 'discriminations[413]',\n",
       " 'discriminations[414]',\n",
       " 'discriminations[415]',\n",
       " 'discriminations[416]',\n",
       " 'discriminations[417]',\n",
       " 'discriminations[418]',\n",
       " 'discriminations[419]',\n",
       " 'discriminations[420]',\n",
       " 'discriminations[421]',\n",
       " 'discriminations[422]',\n",
       " 'discriminations[423]',\n",
       " 'discriminations[424]',\n",
       " 'discriminations[425]',\n",
       " 'discriminations[426]',\n",
       " 'discriminations[427]',\n",
       " 'discriminations[428]',\n",
       " 'discriminations[429]',\n",
       " 'discriminations[430]',\n",
       " 'discriminations[431]',\n",
       " 'discriminations[432]',\n",
       " 'discriminations[433]',\n",
       " 'discriminations[434]',\n",
       " 'discriminations[435]',\n",
       " 'discriminations[436]',\n",
       " 'discriminations[437]',\n",
       " 'discriminations[438]',\n",
       " 'discriminations[439]',\n",
       " 'discriminations[440]',\n",
       " 'discriminations[441]',\n",
       " 'discriminations[442]',\n",
       " 'discriminations[443]',\n",
       " 'discriminations[444]',\n",
       " 'discriminations[445]',\n",
       " 'discriminations[446]',\n",
       " 'discriminations[447]',\n",
       " 'discriminations[448]',\n",
       " 'discriminations[449]',\n",
       " 'discriminations[450]',\n",
       " 'discriminations[451]',\n",
       " 'discriminations[452]',\n",
       " 'discriminations[453]',\n",
       " 'discriminations[454]',\n",
       " 'discriminations[455]',\n",
       " 'discriminations[456]',\n",
       " 'discriminations[457]',\n",
       " 'discriminations[458]',\n",
       " 'discriminations[459]',\n",
       " 'discriminations[460]',\n",
       " 'discriminations[461]',\n",
       " 'discriminations[462]',\n",
       " 'discriminations[463]',\n",
       " 'discriminations[464]',\n",
       " 'discriminations[465]',\n",
       " 'discriminations[466]',\n",
       " 'discriminations[467]',\n",
       " 'discriminations[468]',\n",
       " 'discriminations[469]',\n",
       " 'discriminations[470]',\n",
       " 'discriminations[471]',\n",
       " 'discriminations[472]',\n",
       " 'discriminations[473]',\n",
       " 'discriminations[474]',\n",
       " 'discriminations[475]',\n",
       " 'discriminations[476]',\n",
       " 'discriminations[477]',\n",
       " 'discriminations[478]',\n",
       " 'discriminations[479]',\n",
       " 'discriminations[480]',\n",
       " 'discriminations[481]',\n",
       " 'discriminations[482]',\n",
       " 'discriminations[483]',\n",
       " 'discriminations[484]',\n",
       " 'discriminations[485]',\n",
       " 'discriminations[486]',\n",
       " 'discriminations[487]',\n",
       " 'discriminations[488]',\n",
       " 'discriminations[489]',\n",
       " 'discriminations[490]',\n",
       " 'discriminations[491]',\n",
       " 'discriminations[492]',\n",
       " 'discriminations[493]',\n",
       " 'discriminations[494]',\n",
       " 'discriminations[495]',\n",
       " 'discriminations[496]',\n",
       " 'discriminations[497]',\n",
       " 'discriminations[498]',\n",
       " 'discriminations[499]',\n",
       " 'discriminations[500]',\n",
       " 'discriminations[501]',\n",
       " 'discriminations[502]',\n",
       " 'discriminations[503]',\n",
       " 'discriminations[504]',\n",
       " 'discriminations[505]',\n",
       " 'discriminations[506]',\n",
       " 'discriminations[507]',\n",
       " 'discriminations[508]',\n",
       " 'discriminations[509]',\n",
       " 'discriminations[510]',\n",
       " 'discriminations[511]',\n",
       " 'discriminations[512]',\n",
       " 'discriminations[513]',\n",
       " 'discriminations[514]',\n",
       " 'discriminations[515]',\n",
       " 'discriminations[516]',\n",
       " 'discriminations[517]',\n",
       " 'discriminations[518]',\n",
       " 'discriminations[519]',\n",
       " 'discriminations[520]',\n",
       " 'discriminations[521]',\n",
       " 'discriminations[522]',\n",
       " 'discriminations[523]',\n",
       " 'discriminations[524]',\n",
       " 'discriminations[525]',\n",
       " 'discriminations[526]',\n",
       " 'discriminations[527]',\n",
       " 'discriminations[528]',\n",
       " 'discriminations[529]',\n",
       " 'discriminations[530]',\n",
       " 'discriminations[531]',\n",
       " 'discriminations[532]',\n",
       " 'discriminations[533]',\n",
       " 'discriminations[534]',\n",
       " 'discriminations[535]',\n",
       " 'discriminations[536]',\n",
       " 'discriminations[537]',\n",
       " 'discriminations[538]',\n",
       " 'discriminations[539]',\n",
       " 'discriminations[540]',\n",
       " 'discriminations[541]',\n",
       " 'discriminations[542]',\n",
       " 'discriminations[543]',\n",
       " 'discriminations[544]',\n",
       " 'discriminations[545]',\n",
       " 'discriminations[546]',\n",
       " 'discriminations[547]',\n",
       " 'discriminations[548]',\n",
       " 'discriminations[549]',\n",
       " 'discriminations[550]',\n",
       " 'discriminations[551]',\n",
       " 'discriminations[552]',\n",
       " 'discriminations[553]',\n",
       " 'discriminations[554]',\n",
       " 'discriminations[555]',\n",
       " 'discriminations[556]',\n",
       " 'discriminations[557]',\n",
       " 'discriminations[558]',\n",
       " 'discriminations[559]',\n",
       " 'discriminations[560]',\n",
       " 'discriminations[561]',\n",
       " 'discriminations[562]',\n",
       " 'discriminations[563]',\n",
       " 'discriminations[564]',\n",
       " 'discriminations[565]',\n",
       " 'discriminations[566]',\n",
       " 'discriminations[567]',\n",
       " 'discriminations[568]',\n",
       " 'discriminations[569]',\n",
       " 'discriminations[570]',\n",
       " 'discriminations[571]',\n",
       " 'discriminations[572]',\n",
       " 'discriminations[573]',\n",
       " 'discriminations[574]',\n",
       " 'discriminations[575]',\n",
       " 'discriminations[576]',\n",
       " 'discriminations[577]',\n",
       " 'discriminations[578]',\n",
       " 'discriminations[579]',\n",
       " 'discriminations[580]',\n",
       " 'discriminations[581]',\n",
       " 'discriminations[582]',\n",
       " 'discriminations[583]',\n",
       " 'discriminations[584]',\n",
       " 'discriminations[585]',\n",
       " 'discriminations[586]',\n",
       " 'discriminations[587]',\n",
       " 'discriminations[588]',\n",
       " 'discriminations[589]',\n",
       " 'discriminations[590]',\n",
       " 'discriminations[591]',\n",
       " 'discriminations[592]',\n",
       " 'discriminations[593]',\n",
       " 'discriminations[594]',\n",
       " 'discriminations[595]',\n",
       " 'discriminations[596]',\n",
       " 'discriminations[597]',\n",
       " 'discriminations[598]',\n",
       " 'discriminations[599]',\n",
       " 'discriminations[600]',\n",
       " 'discriminations[601]',\n",
       " 'discriminations[602]',\n",
       " 'discriminations[603]',\n",
       " 'discriminations[604]',\n",
       " 'discriminations[605]',\n",
       " 'discriminations[606]',\n",
       " 'discriminations[607]',\n",
       " 'discriminations[608]',\n",
       " 'discriminations[609]',\n",
       " 'discriminations[610]',\n",
       " 'discriminations[611]',\n",
       " 'discriminations[612]',\n",
       " 'discriminations[613]',\n",
       " 'discriminations[614]',\n",
       " 'discriminations[615]',\n",
       " 'discriminations[616]',\n",
       " 'discriminations[617]',\n",
       " 'discriminations[618]',\n",
       " 'discriminations[619]',\n",
       " 'discriminations[620]',\n",
       " 'discriminations[621]',\n",
       " 'discriminations[622]',\n",
       " 'discriminations[623]',\n",
       " 'discriminations[624]',\n",
       " 'discriminations[625]',\n",
       " 'discriminations[626]',\n",
       " 'discriminations[627]',\n",
       " 'discriminations[628]',\n",
       " 'discriminations[629]',\n",
       " 'discriminations[630]',\n",
       " 'discriminations[631]',\n",
       " 'discriminations[632]',\n",
       " 'discriminations[633]',\n",
       " 'discriminations[634]',\n",
       " 'discriminations[635]',\n",
       " 'discriminations[636]',\n",
       " 'discriminations[637]',\n",
       " 'discriminations[638]',\n",
       " 'discriminations[639]',\n",
       " 'discriminations[640]',\n",
       " 'discriminations[641]',\n",
       " 'discriminations[642]',\n",
       " 'discriminations[643]',\n",
       " 'discriminations[644]',\n",
       " 'discriminations[645]',\n",
       " 'discriminations[646]',\n",
       " 'discriminations[647]',\n",
       " 'discriminations[648]',\n",
       " 'discriminations[649]',\n",
       " 'discriminations[650]',\n",
       " 'discriminations[651]',\n",
       " 'discriminations[652]',\n",
       " 'discriminations[653]',\n",
       " 'discriminations[654]',\n",
       " 'discriminations[655]',\n",
       " 'discriminations[656]',\n",
       " 'discriminations[657]',\n",
       " 'discriminations[658]',\n",
       " 'discriminations[659]',\n",
       " 'discriminations[660]',\n",
       " 'discriminations[661]',\n",
       " 'discriminations[662]',\n",
       " 'discriminations[663]',\n",
       " 'discriminations[664]',\n",
       " 'discriminations[665]',\n",
       " 'discriminations[666]',\n",
       " 'discriminations[667]',\n",
       " 'discriminations[668]',\n",
       " 'discriminations[669]',\n",
       " 'discriminations[670]',\n",
       " 'discriminations[671]',\n",
       " 'discriminations[672]',\n",
       " 'discriminations[673]',\n",
       " 'discriminations[674]',\n",
       " 'discriminations[675]',\n",
       " 'discriminations[676]',\n",
       " 'discriminations[677]',\n",
       " 'discriminations[678]',\n",
       " 'discriminations[679]',\n",
       " 'discriminations[680]',\n",
       " 'discriminations[681]',\n",
       " 'discriminations[682]',\n",
       " 'discriminations[683]',\n",
       " 'discriminations[684]',\n",
       " 'discriminations[685]',\n",
       " 'discriminations[686]',\n",
       " 'discriminations[687]',\n",
       " 'discriminations[688]',\n",
       " 'discriminations[689]',\n",
       " 'discriminations[690]',\n",
       " 'discriminations[691]',\n",
       " 'discriminations[692]',\n",
       " 'discriminations[693]',\n",
       " 'discriminations[694]',\n",
       " 'discriminations[695]',\n",
       " 'discriminations[696]',\n",
       " 'discriminations[697]',\n",
       " 'discriminations[698]',\n",
       " 'discriminations[699]',\n",
       " 'discriminations[700]',\n",
       " 'discriminations[701]',\n",
       " 'discriminations[702]',\n",
       " 'discriminations[703]',\n",
       " 'discriminations[704]',\n",
       " 'discriminations[705]',\n",
       " 'discriminations[706]',\n",
       " 'discriminations[707]',\n",
       " 'discriminations[708]',\n",
       " 'discriminations[709]',\n",
       " 'discriminations[710]',\n",
       " 'discriminations[711]',\n",
       " 'discriminations[712]',\n",
       " 'discriminations[713]',\n",
       " 'discriminations[714]',\n",
       " 'discriminations[715]',\n",
       " 'discriminations[716]',\n",
       " 'discriminations[717]',\n",
       " 'discriminations[718]',\n",
       " 'discriminations[719]',\n",
       " 'discriminations[720]',\n",
       " 'discriminations[721]',\n",
       " 'discriminations[722]',\n",
       " 'discriminations[723]',\n",
       " 'discriminations[724]',\n",
       " 'discriminations[725]',\n",
       " 'discriminations[726]',\n",
       " 'discriminations[727]',\n",
       " 'discriminations[728]',\n",
       " 'discriminations[729]',\n",
       " 'discriminations[730]',\n",
       " 'discriminations[731]',\n",
       " 'discriminations[732]',\n",
       " 'discriminations[733]',\n",
       " 'discriminations[734]',\n",
       " 'discriminations[735]',\n",
       " 'discriminations[736]',\n",
       " 'discriminations[737]',\n",
       " 'discriminations[738]',\n",
       " 'discriminations[739]',\n",
       " 'discriminations[740]',\n",
       " 'discriminations[741]',\n",
       " 'discriminations[742]',\n",
       " 'discriminations[743]',\n",
       " 'discriminations[744]',\n",
       " 'discriminations[745]',\n",
       " 'discriminations[746]',\n",
       " 'discriminations[747]',\n",
       " 'discriminations[748]',\n",
       " 'discriminations[749]',\n",
       " 'discriminations[750]',\n",
       " 'discriminations[751]',\n",
       " 'discriminations[752]',\n",
       " 'discriminations[753]',\n",
       " 'discriminations[754]',\n",
       " 'discriminations[755]',\n",
       " 'discriminations[756]',\n",
       " 'discriminations[757]',\n",
       " 'discriminations[758]',\n",
       " 'discriminations[759]',\n",
       " 'discriminations[760]',\n",
       " 'discriminations[761]',\n",
       " 'discriminations[762]',\n",
       " 'discriminations[763]',\n",
       " 'discriminations[764]',\n",
       " 'discriminations[765]',\n",
       " 'discriminations[766]',\n",
       " 'discriminations[767]',\n",
       " 'discriminations[768]',\n",
       " 'discriminations[769]',\n",
       " 'discriminations[770]',\n",
       " 'discriminations[771]',\n",
       " 'discriminations[772]',\n",
       " 'discriminations[773]',\n",
       " 'discriminations[774]',\n",
       " 'discriminations[775]',\n",
       " 'discriminations[776]',\n",
       " 'discriminations[777]',\n",
       " 'discriminations[778]',\n",
       " 'discriminations[779]',\n",
       " 'discriminations[780]',\n",
       " 'discriminations[781]',\n",
       " 'discriminations[782]',\n",
       " 'discriminations[783]',\n",
       " 'discriminations[784]',\n",
       " 'discriminations[785]',\n",
       " 'discriminations[786]',\n",
       " 'discriminations[787]',\n",
       " 'discriminations[788]',\n",
       " 'discriminations[789]',\n",
       " 'discriminations[790]',\n",
       " 'discriminations[791]',\n",
       " 'discriminations[792]',\n",
       " 'discriminations[793]',\n",
       " 'discriminations[794]',\n",
       " 'discriminations[795]',\n",
       " 'discriminations[796]',\n",
       " 'discriminations[797]',\n",
       " 'discriminations[798]',\n",
       " 'discriminations[799]',\n",
       " 'discriminations[800]',\n",
       " 'discriminations[801]',\n",
       " 'discriminations[802]',\n",
       " 'discriminations[803]',\n",
       " 'discriminations[804]',\n",
       " 'discriminations[805]',\n",
       " 'discriminations[806]',\n",
       " 'discriminations[807]',\n",
       " 'discriminations[808]',\n",
       " 'discriminations[809]',\n",
       " 'discriminations[810]',\n",
       " 'discriminations[811]',\n",
       " 'discriminations[812]',\n",
       " 'discriminations[813]',\n",
       " 'discriminations[814]',\n",
       " 'discriminations[815]',\n",
       " 'discriminations[816]',\n",
       " 'discriminations[817]',\n",
       " 'discriminations[818]',\n",
       " 'discriminations[819]',\n",
       " 'discriminations[820]',\n",
       " 'discriminations[821]',\n",
       " 'discriminations[822]',\n",
       " 'discriminations[823]',\n",
       " 'discriminations[824]',\n",
       " 'discriminations[825]',\n",
       " 'discriminations[826]',\n",
       " 'discriminations[827]',\n",
       " 'discriminations[828]',\n",
       " 'discriminations[829]',\n",
       " 'discriminations[830]',\n",
       " 'discriminations[831]',\n",
       " 'discriminations[832]',\n",
       " 'discriminations[833]',\n",
       " 'discriminations[834]',\n",
       " 'discriminations[835]',\n",
       " 'discriminations[836]',\n",
       " 'discriminations[837]',\n",
       " 'discriminations[838]',\n",
       " 'discriminations[839]',\n",
       " 'discriminations[840]',\n",
       " 'discriminations[841]',\n",
       " 'discriminations[842]',\n",
       " 'discriminations[843]',\n",
       " 'discriminations[844]',\n",
       " 'discriminations[845]',\n",
       " 'discriminations[846]',\n",
       " 'discriminations[847]',\n",
       " 'discriminations[848]',\n",
       " 'discriminations[849]',\n",
       " 'discriminations[850]',\n",
       " 'discriminations[851]',\n",
       " 'discriminations[852]',\n",
       " 'discriminations[853]',\n",
       " 'discriminations[854]',\n",
       " 'discriminations[855]',\n",
       " 'discriminations[856]',\n",
       " 'discriminations[857]',\n",
       " 'discriminations[858]',\n",
       " 'discriminations[859]',\n",
       " 'discriminations[860]',\n",
       " 'discriminations[861]',\n",
       " 'discriminations[862]',\n",
       " 'discriminations[863]',\n",
       " 'discriminations[864]',\n",
       " 'discriminations[865]',\n",
       " 'discriminations[866]',\n",
       " 'discriminations[867]',\n",
       " 'discriminations[868]',\n",
       " 'discriminations[869]',\n",
       " 'discriminations[870]',\n",
       " 'discriminations[871]',\n",
       " 'discriminations[872]',\n",
       " 'discriminations[873]',\n",
       " 'discriminations[874]',\n",
       " 'discriminations[875]',\n",
       " 'discriminations[876]',\n",
       " 'discriminations[877]',\n",
       " 'discriminations[878]',\n",
       " 'discriminations[879]',\n",
       " 'discriminations[880]',\n",
       " 'discriminations[881]',\n",
       " 'discriminations[882]',\n",
       " 'discriminations[883]',\n",
       " 'discriminations[884]',\n",
       " 'discriminations[885]',\n",
       " 'discriminations[886]',\n",
       " 'discriminations[887]',\n",
       " 'discriminations[888]',\n",
       " 'discriminations[889]',\n",
       " 'discriminations[890]',\n",
       " 'discriminations[891]',\n",
       " 'discriminations[892]',\n",
       " 'discriminations[893]',\n",
       " 'discriminations[894]',\n",
       " 'discriminations[895]',\n",
       " 'discriminations[896]',\n",
       " 'discriminations[897]',\n",
       " 'discriminations[898]',\n",
       " 'discriminations[899]',\n",
       " 'discriminations[900]',\n",
       " 'discriminations[901]',\n",
       " 'discriminations[902]',\n",
       " 'discriminations[903]',\n",
       " 'discriminations[904]',\n",
       " 'discriminations[905]',\n",
       " 'discriminations[906]',\n",
       " 'discriminations[907]',\n",
       " 'discriminations[908]',\n",
       " 'discriminations[909]',\n",
       " 'discriminations[910]',\n",
       " 'discriminations[911]',\n",
       " 'discriminations[912]',\n",
       " 'discriminations[913]',\n",
       " 'discriminations[914]',\n",
       " 'discriminations[915]',\n",
       " 'discriminations[916]',\n",
       " 'discriminations[917]',\n",
       " 'discriminations[918]',\n",
       " 'discriminations[919]',\n",
       " 'discriminations[920]',\n",
       " 'discriminations[921]',\n",
       " 'discriminations[922]',\n",
       " 'discriminations[923]',\n",
       " 'discriminations[924]',\n",
       " 'discriminations[925]',\n",
       " 'discriminations[926]',\n",
       " 'discriminations[927]',\n",
       " 'discriminations[928]',\n",
       " 'discriminations[929]',\n",
       " 'discriminations[930]',\n",
       " 'discriminations[931]',\n",
       " 'discriminations[932]',\n",
       " 'discriminations[933]',\n",
       " 'discriminations[934]',\n",
       " 'discriminations[935]',\n",
       " 'discriminations[936]',\n",
       " 'discriminations[937]',\n",
       " 'discriminations[938]',\n",
       " 'discriminations[939]',\n",
       " 'discriminations[940]',\n",
       " 'discriminations[941]',\n",
       " 'discriminations[942]',\n",
       " 'discriminations[943]',\n",
       " 'discriminations[944]',\n",
       " 'discriminations[945]',\n",
       " 'discriminations[946]',\n",
       " 'discriminations[947]',\n",
       " 'discriminations[948]',\n",
       " 'discriminations[949]',\n",
       " 'discriminations[950]',\n",
       " 'discriminations[951]',\n",
       " 'discriminations[952]',\n",
       " 'discriminations[953]',\n",
       " 'discriminations[954]',\n",
       " 'discriminations[955]',\n",
       " 'discriminations[956]',\n",
       " 'discriminations[957]',\n",
       " 'discriminations[958]',\n",
       " 'discriminations[959]',\n",
       " 'discriminations[960]',\n",
       " 'discriminations[961]',\n",
       " 'discriminations[962]',\n",
       " 'discriminations[963]',\n",
       " 'discriminations[964]',\n",
       " 'discriminations[965]',\n",
       " 'discriminations[966]',\n",
       " 'discriminations[967]',\n",
       " 'discriminations[968]',\n",
       " 'discriminations[969]',\n",
       " 'discriminations[970]',\n",
       " 'discriminations[971]',\n",
       " 'discriminations[972]',\n",
       " 'discriminations[973]',\n",
       " 'discriminations[974]',\n",
       " 'discriminations[975]',\n",
       " 'discriminations[976]',\n",
       " 'discriminations[977]',\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(summary.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get point estimates and uncertainty\n",
    "def get_parameter_estimates(trace):\n",
    "    estimates = {\n",
    "        'abilities': {\n",
    "            'mean': trace.posterior['abilities'].mean(dim=['chain', 'draw']).values,\n",
    "            'std': trace.posterior['abilities'].std(dim=['chain', 'draw']).values,\n",
    "            'hdi': az.hdi(trace, var_names=['abilities'])\n",
    "        },\n",
    "        'discriminations': {\n",
    "            'mean': trace.posterior['discriminations'].mean(dim=['chain', 'draw']).values,\n",
    "            'std': trace.posterior['discriminations'].std(dim=['chain', 'draw']).values,\n",
    "            'hdi': az.hdi(trace, var_names=['discriminations'])\n",
    "        },\n",
    "        'difficulties': {\n",
    "            'mean': trace.posterior['difficulties'].mean(dim=['chain', 'draw']).values,\n",
    "            'std': trace.posterior['difficulties'].std(dim=['chain', 'draw']).values,\n",
    "            'hdi': az.hdi(trace, var_names=['difficulties'])\n",
    "        }\n",
    "    }\n",
    "    return estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = get_parameter_estimates(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mistral-Large-2': 0.4580667032974997,\n",
       " 'Llama-3.1-70B-Instruct': -0.07793879274298017,\n",
       " 'Claude-3.5 (Sonnet)': -0.6700002913364688,\n",
       " 'Mistral-8x7b-Instruct': -2.3490229216075624,\n",
       " 'Command-R+': -1.1730601421949194,\n",
       " 'Llama-3.1-405B-Instruct': 0.5921608201060119,\n",
       " 'Llama-3.1-8B-Instruct': -0.9785653849577762,\n",
       " 'GPT-4o': 0.4981269288420167,\n",
       " 'Llama-3-70B-Instruct': -0.607989293845749,\n",
       " 'PaperQA2': 0.05055868388896333,\n",
       " 'Gemma-1.1-7B-it': -4.895052190773771,\n",
       " 'Gemma-2-9B-it': -0.883897051887834,\n",
       " 'Llama-2-70B Chat': -4.066615761763882,\n",
       " 'Galatica-120b': -8.370154796213088,\n",
       " 'Llama-3-8B-Instruct': -0.9035605387637059,\n",
       " 'Gemini-Pro': -0.9622151329026539,\n",
       " 'o1': 1.0158636748513077,\n",
       " 'GPT-4': -2.8381532745919102,\n",
       " 'Phi-3-Medium-4k-Instruct': -0.8452802334086583,\n",
       " 'Claude-3 (Opus)': -2.2368780397563657,\n",
       " 'GPT-3.5 Turbo Zero-T': -1.1187322243879676,\n",
       " 'Claude-2-Zero-T': -7.556805116366585}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(analyzer.model_ids, estimates['abilities']['mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
