{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# irt\n",
    "\n",
    "> Some basic tooling in item response theory for analyzing the results of ML benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp irt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will use item response theory (IRT) to analyze benchmark results. \n",
    "\n",
    "A common model in IRT is the Rasch model, which described the probability of a correct response ($P(X=1)$) as a function of the ability of the person ($\\theta_n$) and the difficulty ($\\beta_i$) of the item: \n",
    "\n",
    "$$\n",
    "P(X_{ni} =1| \\theta_n, \\beta_i) = \\frac{\\exp\\{\\theta_n - \\beta_i\\}}{1 + \\exp\\{\\theta_n - \\beta_i\\}}\n",
    "$$\n",
    "\n",
    "We can make this more general by adding a discrimination parameter $\\alpha_i$: This parameter describes how well the item discriminates between models of different abilities. The probability of a correct response is then given by:\n",
    "\n",
    "$$\n",
    "P(X_{ni} =1| \\theta_n, \\beta_i, \\alpha_i) = \\frac{\\exp\\{\\alpha_i(\\theta_n - \\beta_i)\\}}{1 + \\exp\\{\\alpha_i(\\theta_n - \\beta_i)\\}}\n",
    "$$\n",
    "\n",
    "This is the 2PL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import numpy as np \n",
    "from girth import twopl_mml, rasch_mml, ability_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kevinmaikjablonka/Downloads/model_score_dict.pkl', 'rb') as f:\n",
    "    model_score_dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canary_0</th>\n",
       "      <th>description_0</th>\n",
       "      <th>keywords_0</th>\n",
       "      <th>llm_extraction_count_0</th>\n",
       "      <th>metrics_correct_classes</th>\n",
       "      <th>metrics_extra_classes</th>\n",
       "      <th>metrics_f1</th>\n",
       "      <th>metrics_hamming</th>\n",
       "      <th>metrics_incorrect_classes</th>\n",
       "      <th>metrics_missed_classes</th>\n",
       "      <th>...</th>\n",
       "      <th>is_analytical_chemistry</th>\n",
       "      <th>is_periodic_table</th>\n",
       "      <th>is_general_chemistry_exam</th>\n",
       "      <th>is_biomolecular</th>\n",
       "      <th>is_xray</th>\n",
       "      <th>is_materials_science</th>\n",
       "      <th>is_molsim</th>\n",
       "      <th>requires_calculation</th>\n",
       "      <th>is_preference</th>\n",
       "      <th>is_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>ghs pictograms</td>\n",
       "      <td>[pubchem, pictograms, safety]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Predicting the appropriate stoichiometric coef...</td>\n",
       "      <td>[stoichiometric coefficient, physical-chemistr...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Chemical mixing compatibility test</td>\n",
       "      <td>[chemicals, safety compatibility test, reactiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Diazonium Salts characteristics questions, inc...</td>\n",
       "      <td>[chemistry, molecules, diazonium salts, organi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Amines, Aromatic characteristics questions, in...</td>\n",
       "      <td>[amines, aromatic, requires-knowledge, safety,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Solid state chemistry questions related to poi...</td>\n",
       "      <td>[solid state chemistry, requires-reasoning, di...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>General questions on apatite</td>\n",
       "      <td>[apatite, substitutions in apatite, chemical f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Chemical mixing compatibility test</td>\n",
       "      <td>[chemicals, safety compatibility test, reactiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Preference for further drug development</td>\n",
       "      <td>[preference, requires-intuition]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...</td>\n",
       "      <td>Predicting the total number of structural isom...</td>\n",
       "      <td>[isomers, requires-reasoning, dfficulty-basic]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2854 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               canary_0  \\\n",
       "0     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "1     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "3     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "4     BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "...                                                 ...   \n",
       "2849  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2850  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2851  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2852  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "2853  BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...   \n",
       "\n",
       "                                          description_0  \\\n",
       "0                                        ghs pictograms   \n",
       "1     Predicting the appropriate stoichiometric coef...   \n",
       "2                    Chemical mixing compatibility test   \n",
       "3     Diazonium Salts characteristics questions, inc...   \n",
       "4     Amines, Aromatic characteristics questions, in...   \n",
       "...                                                 ...   \n",
       "2849  Solid state chemistry questions related to poi...   \n",
       "2850                       General questions on apatite   \n",
       "2851                 Chemical mixing compatibility test   \n",
       "2852            Preference for further drug development   \n",
       "2853  Predicting the total number of structural isom...   \n",
       "\n",
       "                                             keywords_0  \\\n",
       "0                         [pubchem, pictograms, safety]   \n",
       "1     [stoichiometric coefficient, physical-chemistr...   \n",
       "2     [chemicals, safety compatibility test, reactiv...   \n",
       "3     [chemistry, molecules, diazonium salts, organi...   \n",
       "4     [amines, aromatic, requires-knowledge, safety,...   \n",
       "...                                                 ...   \n",
       "2849  [solid state chemistry, requires-reasoning, di...   \n",
       "2850  [apatite, substitutions in apatite, chemical f...   \n",
       "2851  [chemicals, safety compatibility test, reactiv...   \n",
       "2852                   [preference, requires-intuition]   \n",
       "2853     [isomers, requires-reasoning, dfficulty-basic]   \n",
       "\n",
       "      llm_extraction_count_0  metrics_correct_classes  metrics_extra_classes  \\\n",
       "0                          0                      0.0                    1.0   \n",
       "1                          0                      NaN                    NaN   \n",
       "2                          0                      3.0                    3.0   \n",
       "3                          0                      1.0                    0.0   \n",
       "4                          0                      1.0                    0.0   \n",
       "...                      ...                      ...                    ...   \n",
       "2849                       0                      1.0                    0.0   \n",
       "2850                       0                      1.0                    0.0   \n",
       "2851                       0                      2.0                    3.0   \n",
       "2852                       0                      1.0                    0.0   \n",
       "2853                       0                      NaN                    NaN   \n",
       "\n",
       "      metrics_f1  metrics_hamming  metrics_incorrect_classes  \\\n",
       "0       0.000000              2.0                        1.0   \n",
       "1            NaN              NaN                        NaN   \n",
       "2       0.666667              1.0                        3.0   \n",
       "3       1.000000              0.0                        0.0   \n",
       "4       1.000000              0.0                        0.0   \n",
       "...          ...              ...                        ...   \n",
       "2849    1.000000              0.0                        0.0   \n",
       "2850    1.000000              0.0                        0.0   \n",
       "2851    0.571429              1.5                        3.0   \n",
       "2852    1.000000              0.0                        0.0   \n",
       "2853         NaN              NaN                        NaN   \n",
       "\n",
       "      metrics_missed_classes  ...  is_analytical_chemistry  is_periodic_table  \\\n",
       "0                        1.0  ...                    False              False   \n",
       "1                        NaN  ...                    False              False   \n",
       "2                        0.0  ...                    False              False   \n",
       "3                        0.0  ...                    False              False   \n",
       "4                        0.0  ...                    False              False   \n",
       "...                      ...  ...                      ...                ...   \n",
       "2849                     0.0  ...                    False              False   \n",
       "2850                     0.0  ...                    False              False   \n",
       "2851                     0.0  ...                    False              False   \n",
       "2852                     0.0  ...                    False              False   \n",
       "2853                     NaN  ...                    False              False   \n",
       "\n",
       "      is_general_chemistry_exam is_biomolecular is_xray is_materials_science  \\\n",
       "0                         False           False   False                False   \n",
       "1                         False           False   False                False   \n",
       "2                         False           False   False                False   \n",
       "3                         False           False   False                False   \n",
       "4                         False           False   False                False   \n",
       "...                         ...             ...     ...                  ...   \n",
       "2849                      False           False   False                False   \n",
       "2850                      False           False   False                 True   \n",
       "2851                      False           False   False                False   \n",
       "2852                      False           False   False                False   \n",
       "2853                      False           False   False                False   \n",
       "\n",
       "     is_molsim requires_calculation is_preference  is_name  \n",
       "0        False                  NaN         False    False  \n",
       "1        False                  NaN         False    False  \n",
       "2        False                  NaN         False    False  \n",
       "3        False                  NaN         False    False  \n",
       "4        False                  NaN         False    False  \n",
       "...        ...                  ...           ...      ...  \n",
       "2849     False                  NaN         False    False  \n",
       "2850     False                  NaN         False    False  \n",
       "2851     False                  NaN         False    False  \n",
       "2852     False                  NaN          True    False  \n",
       "2853     False                  NaN         False    False  \n",
       "\n",
       "[2854 rows x 77 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_dicts['overall']['Claude-2-Zero-T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ScoringType(Enum): \n",
    "    BINARY = 'binary'\n",
    "    PARTIAL = 'partial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a container to store meta information for each question (item). We will track some identifier and what type of scoring the question uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@dataclass\n",
    "class QuestionMetadata:\n",
    "    \"\"\"Base class for question metadata\"\"\"\n",
    "    question_id: str\n",
    "    scoring_type: ScoringType\n",
    "\n",
    "    def compute_score(self, response) -> float:\n",
    "        \"\"\"Base method for computing scores\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@dataclass\n",
    "class BinaryQuestionMetadata(QuestionMetadata):\n",
    "    \"\"\"Metadata for binary scored questions\"\"\"\n",
    "    def __init__(self, question_id: str):\n",
    "        super().__init__(question_id, ScoringType.BINARY)\n",
    "\n",
    "    def compute_score(self, row, column: str='all_correct_') -> float:\n",
    "        \"\"\"Use the all_correct column directly\"\"\"\n",
    "        return float(row[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class BenchmarkAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model_dataframes: Dict[str, pd.DataFrame] = {}\n",
    "        self.question_metadata: Dict[str, QuestionMetadata] = {}\n",
    "        self.score_matrix = None\n",
    "        self.model_ids = None\n",
    "\n",
    "    def add_model_results(self, model_id: str, results_df: pd.DataFrame):\n",
    "        \"\"\"Add a model's results DataFrame\"\"\"\n",
    "        self.model_dataframes[model_id] = results_df\n",
    "\n",
    "    def add_question_metadata(self, metadata: QuestionMetadata):\n",
    "        \"\"\"Add metadata for a question\"\"\"\n",
    "        self.question_metadata[metadata.question_id] = metadata\n",
    "\n",
    "    def compute_score_matrix(self) -> np.ndarray:\n",
    "        \"\"\"Compute score matrix using metadata-specific scoring\"\"\"\n",
    "        if not self.model_dataframes or not self.question_metadata:\n",
    "            raise ValueError(\"Need both model results and question metadata\")\n",
    "\n",
    "        self.model_ids = list(self.model_dataframes.keys())\n",
    "        question_ids = list(self.question_metadata.keys())\n",
    "\n",
    "        # Initialize score matrix\n",
    "        self.score_matrix = np.full(\n",
    "            (len(self.model_ids), len(question_ids)), \n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "        # Compute scores\n",
    "        for model_idx, model_id in enumerate(self.model_ids):\n",
    "            df = self.model_dataframes[model_id]\n",
    "            for q_idx, q_id in enumerate(question_ids):\n",
    "                if q_id not in df.index:\n",
    "                    continue\n",
    "\n",
    "                metadata = self.question_metadata[q_id]\n",
    "                row = df.loc[q_id]\n",
    "\n",
    "                self.score_matrix[model_idx, q_idx] = metadata.compute_score(row)\n",
    "\n",
    "\n",
    "        return self.score_matrix\n",
    "\n",
    "    def fit_irt(self, model='2pl') -> Dict[str, pd.DataFrame]:\n",
    "        if self.score_matrix is None:\n",
    "            self.compute_score_matrix()\n",
    "\n",
    "        binary_matrix = (self.score_matrix >= 0.5).astype(int).T #  needs to be [n_items, n_participants]\n",
    "        \n",
    "        if model == '2pl':\n",
    "            # options = {\n",
    "            # 'max_iteration': 200,\n",
    "            # 'quadrature_n': 61,  # More quadrature points for better precision\n",
    "            # 'quadrature_bounds': (-6, 6),  # Default bounds\n",
    "            # 'estimate_distribution': True  # Allow distribution estimation\n",
    "            # }\n",
    "\n",
    "            results = twopl_mml(binary_matrix)\n",
    "            difficulties = results['Difficulty']\n",
    "            discriminations = results['Discrimination']\n",
    "        else:  # rasch\n",
    "            results = rasch_mml(binary_matrix)\n",
    "            difficulties = results['Difficulty']\n",
    "            discriminations = np.ones_like(difficulties) \n",
    "        \n",
    "        abilities = ability_mle(\n",
    "            binary_matrix,  \n",
    "            difficulties,\n",
    "            discriminations,\n",
    "            no_estimate=np.nan  \n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'difficulties': difficulties,\n",
    "            'discriminations': discriminations,\n",
    "            'abilities': abilities, \n",
    "            'binary_matrix': binary_matrix\n",
    "        }\n",
    "\n",
    "\n",
    "    def analyze_extreme_items(difficulties, discriminations, question_ids, threshold=0.95):\n",
    "        \"\"\"Identify items with extreme parameters\"\"\"\n",
    "        extreme_items = pd.DataFrame({\n",
    "            'question_id': question_ids,\n",
    "            'difficulty': difficulties,\n",
    "            'discrimination': discriminations\n",
    "        })\n",
    "\n",
    "        # Find items with extreme values\n",
    "        extreme_items['is_extreme'] = (\n",
    "            (discriminations > threshold * 5.0) |  # High discrimination\n",
    "            (difficulties > threshold * 6.0) |     # Very difficult\n",
    "            (difficulties < -4.0)                  # Very easy\n",
    "        )\n",
    "\n",
    "        return extreme_items[extreme_items['is_extreme']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's the class with some of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = BenchmarkAnalyzer()\n",
    "\n",
    "for model_id, df in model_score_dicts['overall'].items():\n",
    "    analyzer.add_model_results(model_id, df)\n",
    "\n",
    "\n",
    "# for now, let's just add the binary questions\n",
    "for i, row in model_score_dicts['overall']['Claude-2-Zero-T'].iterrows():\n",
    "    if row['metrics_hamming']:\n",
    "        analyzer.add_question_metadata(BinaryQuestionMetadata(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/irt/lib/python3.11/site-packages/girth/unidimensional/dichotomous/rasch_mml.py:108: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log(otpt).dot(counts)\n"
     ]
    }
   ],
   "source": [
    "results = analyzer.fit_irt(model='rasch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'difficulties': array([ 2.17320999,  0.22051166,  5.99993935, ..., -1.78526175,\n",
       "         1.46119429, -0.22054479]),\n",
       " 'discriminations': array([1., 1., 1., ..., 1., 1., 1.]),\n",
       " 'abilities': array([ 0.92062274,  0.70085661,  0.43172056, -0.33257593,  0.18210808,\n",
       "         0.97653286,  0.26776643,  0.95411399,  0.46383346,  0.73349057,\n",
       "        -1.47287807,  0.30697452, -1.099009  , -4.0792575 ,  0.28559071,\n",
       "         0.27133169,  1.18214098, -0.5245331 ,  0.32122829, -0.2613409 ,\n",
       "         0.20711413, -3.02995173]),\n",
       " 'binary_matrix': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 1, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mistral-Large-2': 0.9206227382517711,\n",
       " 'Llama-3.1-70B-Instruct': 0.7008566079326864,\n",
       " 'Claude-3.5 (Sonnet)': 0.43172056318578506,\n",
       " 'Mistral-8x7b-Instruct': -0.33257592815906706,\n",
       " 'Command-R+': 0.18210807975250953,\n",
       " 'Llama-3.1-405B-Instruct': 0.976532863706392,\n",
       " 'Llama-3.1-8B-Instruct': 0.26776643434833536,\n",
       " 'GPT-4o': 0.954113987494647,\n",
       " 'Llama-3-70B-Instruct': 0.46383345663883774,\n",
       " 'PaperQA2': 0.7334905687001801,\n",
       " 'Gemma-1.1-7B-it': -1.472878071397841,\n",
       " 'Gemma-2-9B-it': 0.30697451785597074,\n",
       " 'Llama-2-70B Chat': -1.0990090007354893,\n",
       " 'Galatica-120b': -4.079257501775907,\n",
       " 'Llama-3-8B-Instruct': 0.2855907076410609,\n",
       " 'Gemini-Pro': 0.2713316860822229,\n",
       " 'o1': 1.1821409799492104,\n",
       " 'GPT-4': -0.5245330961997795,\n",
       " 'Phi-3-Medium-4k-Instruct': 0.32122828793906116,\n",
       " 'Claude-3 (Opus)': -0.2613409044033738,\n",
       " 'GPT-3.5 Turbo Zero-T': 0.2071141267589506,\n",
       " 'Claude-2-Zero-T': -3.0299517299011396}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(analyzer.model_ids, results['abilities']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be quite different from a naive ranking based on taking the mean of the scores.\n",
    "Let's perform some more detailed analysis what causes the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22,)\n",
      "                          irt_ability  avg_score  irt_rank  avg_rank\n",
      "model_id                                                            \n",
      "Mistral-Large-2              0.920623   0.545849       4.0       4.0\n",
      "Llama-3.1-70B-Instruct       0.700857   0.508674       6.0       6.0\n",
      "Claude-3.5 (Sonnet)          0.431721   0.462206       8.0       8.0\n",
      "Mistral-8x7b-Instruct       -0.332576   0.331475      17.0      17.0\n",
      "Command-R+                   0.182108   0.418835      15.0      15.0\n",
      "Llama-3.1-405B-Instruct      0.976533   0.555143       2.0       2.0\n",
      "Llama-3.1-8B-Instruct        0.267766   0.433705      13.0      13.0\n",
      "GPT-4o                       0.954114   0.551425       3.0       3.0\n",
      "Llama-3-70B-Instruct         0.463833   0.467782       7.0       7.0\n",
      "PaperQA2                     0.733491   0.514250       5.0       5.0\n",
      "Gemma-1.1-7B-it             -1.472878   0.169765      20.0      20.0\n",
      "Gemma-2-9B-it                0.306975   0.440520      10.0      10.0\n",
      "Llama-2-70B Chat            -1.099009   0.216233      19.0      19.0\n",
      "Galatica-120b               -4.079258   0.019827      22.0      22.0\n",
      "Llama-3-8B-Instruct          0.285591   0.436803      11.0      11.0\n",
      "Gemini-Pro                   0.271332   0.434325      12.0      12.0\n",
      "o1                           1.182141   0.588600       1.0       1.0\n",
      "GPT-4                       -0.524533   0.300496      18.0      18.0\n",
      "Phi-3-Medium-4k-Instruct     0.321228   0.442999       9.0       9.0\n",
      "Claude-3 (Opus)             -0.261341   0.343247      16.0      16.0\n",
      "GPT-3.5 Turbo Zero-T         0.207114   0.423172      14.0      14.0\n",
      "Claude-2-Zero-T             -3.029952   0.050805      21.0      21.0\n",
      "\n",
      "Models with largest ranking differences:\n",
      "Empty DataFrame\n",
      "Columns: [irt_ability, avg_score, irt_rank, avg_rank, rank_diff]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def analyze_influential_questions(binary_matrix, abilities, difficulties, discriminations, model_ids, question_ids):\n",
    "    \"\"\"Analyze which questions cause the biggest differences between IRT and average scoring\"\"\"\n",
    "\n",
    "    # Get both scoring methods\n",
    "    avg_scores = np.mean(binary_matrix.T, axis=1)\n",
    "    print(avg_scores.shape)\n",
    "\n",
    "    # Create base comparison DataFrame\n",
    "    model_comparison = pd.DataFrame({\n",
    "        'model_id': model_ids,\n",
    "        'irt_ability': abilities,\n",
    "        'avg_score': avg_scores,\n",
    "        'irt_rank': pd.Series(abilities).rank(ascending=False),\n",
    "        'avg_rank': pd.Series(avg_scores).rank(ascending=False)\n",
    "    }).set_index('model_id')\n",
    "    print(model_comparison)\n",
    "\n",
    "    # Find models with large ranking differences\n",
    "    model_comparison['rank_diff'] = model_comparison['avg_rank'] - model_comparison['irt_rank']\n",
    "    interesting_models = model_comparison[abs(model_comparison['rank_diff']) > 2]\n",
    "\n",
    "    # Analyze question characteristics for these models\n",
    "    question_analysis = pd.DataFrame({\n",
    "        'question_id': question_ids,\n",
    "        'difficulty': difficulties,\n",
    "        'discrimination': discriminations,\n",
    "        'avg_success_rate': np.mean(binary_matrix.T, axis=0)\n",
    "    })\n",
    "\n",
    "    # For each interesting model, analyze its response pattern\n",
    "    for model_id in interesting_models.index:\n",
    "        model_idx = model_ids.index(model_id)\n",
    "        responses = binary_matrix[model_idx]\n",
    "\n",
    "        # Calculate contribution to IRT score\n",
    "        # Higher contribution when succeeding on difficult/discriminating items\n",
    "        question_analysis[f'{model_id}_contribution'] = (\n",
    "            responses * discriminations * (difficulties - abilities[model_idx])\n",
    "        )\n",
    "\n",
    "        # Add raw response\n",
    "        question_analysis[f'{model_id}_response'] = responses\n",
    "\n",
    "    # Find most influential questions\n",
    "    influential_questions = question_analysis[\n",
    "        (question_analysis['discrimination'] > np.percentile(discriminations, 75)) |\n",
    "        (abs(question_analysis['difficulty']) > 2)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        'model_differences': interesting_models,\n",
    "        'influential_questions': influential_questions.sort_values('discrimination', ascending=False)\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "influential_analysis_results = analyze_influential_questions(\n",
    "    results['binary_matrix'],\n",
    "    results['abilities'], \n",
    "    results['difficulties'], \n",
    "    results['discriminations'], \n",
    "    analyzer.model_ids, \n",
    "    list(analyzer.question_metadata.keys())\n",
    ")\n",
    "\n",
    "print(\"\\nModels with largest ranking differences:\")\n",
    "print(influential_analysis_results['model_differences'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most influential questions:\n",
      "     question_id  difficulty  discrimination  avg_success_rate\n",
      "0              0    2.173210             1.0          0.136364\n",
      "821         1450    2.173210             1.0          0.136364\n",
      "892         1585    5.999939             1.0          0.000000\n",
      "884         1566    2.679903             1.0          0.090909\n",
      "862         1527   -3.477644             1.0          0.954545\n",
      "849         1498    2.173210             1.0          0.136364\n",
      "848         1497    2.173210             1.0          0.136364\n",
      "835         1471    3.477478             1.0          0.045455\n",
      "828         1462    5.999939             1.0          0.000000\n",
      "824         1454    2.173210             1.0          0.136364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nMost influential questions:\")\n",
    "print(influential_analysis_results['influential_questions'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "canary_0                   BENCHMARK DATA SHOULD NEVER APPEAR IN TRAINING...\n",
       "description_0                                    Distribution of antibiotics\n",
       "keywords_0                 [antibiotic, distribution, pharmacokinetics, r...\n",
       "llm_extraction_count_0                                                     0\n",
       "metrics_correct_classes                                                  1.0\n",
       "                                                 ...                        \n",
       "is_materials_science                                                   False\n",
       "is_molsim                                                              False\n",
       "requires_calculation                                                     NaN\n",
       "is_preference                                                          False\n",
       "is_name                                                                False\n",
       "Name: 1879, Length: 77, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_dicts['overall']['GPT-4'].iloc[1879]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 330x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "influential_analysis_results['influential_questions']['difficulty'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>discrimination</th>\n",
       "      <th>avg_success_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1527</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>1590</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1595</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1778</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1775</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1596</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>977</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>946</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2563</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>2386</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1900</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>2801</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>2658</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>2631</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>2374</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>2113</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>2282</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>366</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>186</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>497</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>694</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>769</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>664</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>528</td>\n",
       "      <td>-3.477644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>523</td>\n",
       "      <td>-2.173275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>609</td>\n",
       "      <td>-2.679993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id  difficulty  discrimination  avg_success_rate\n",
       "862          1527   -3.477644             1.0          0.954545\n",
       "894          1590   -2.173275             1.0          0.863636\n",
       "898          1595   -2.173275             1.0          0.863636\n",
       "998          1778   -2.173275             1.0          0.863636\n",
       "996          1775   -2.679993             1.0          0.909091\n",
       "899          1596   -2.173275             1.0          0.863636\n",
       "563           977   -2.173275             1.0          0.863636\n",
       "544           946   -2.173275             1.0          0.863636\n",
       "1448         2563   -3.477644             1.0          0.954545\n",
       "1349         2386   -2.679993             1.0          0.909091\n",
       "1069         1900   -2.173275             1.0          0.863636\n",
       "1582         2801   -3.477644             1.0          0.954545\n",
       "1492         2658   -2.679993             1.0          0.909091\n",
       "1481         2631   -2.679993             1.0          0.909091\n",
       "1343         2374   -2.679993             1.0          0.909091\n",
       "1192         2113   -2.679993             1.0          0.909091\n",
       "1290         2282   -2.173275             1.0          0.863636\n",
       "207           366   -2.173275             1.0          0.863636\n",
       "16             25   -2.679993             1.0          0.909091\n",
       "106           186   -3.477644             1.0          0.954545\n",
       "278           497   -2.173275             1.0          0.863636\n",
       "400           694   -2.679993             1.0          0.909091\n",
       "439           769   -2.679993             1.0          0.909091\n",
       "382           664   -2.173275             1.0          0.863636\n",
       "296           528   -3.477644             1.0          0.954545\n",
       "291           523   -2.173275             1.0          0.863636\n",
       "343           609   -2.679993             1.0          0.909091"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influential_analysis_results['influential_questions'][influential_analysis_results['influential_questions']['difficulty']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following is a question about chemistry.\\n\\nQuestion: The reaction of sulfur dioxide with calcium carbonate and oxygen is 2SO2 + 2CaCO3 + O2 -> xCaSO4 + 2CO2. What is x?\\n\\nYou MUST include the final answer within the following tags: [ANSWER] and [/ANSWER].\\nFor example, '[ANSWER]<answer>[/ANSWER]', where <answer> is only one number. Always answer in exactly this format, with ONE NUMBER between the two tags, even if you are unsure. Use dots as decimal separator. We require this because we use automatic parsing.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_dicts['overall']['GPT-4'].iloc[1590]['prompt_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can make it Bayesian with `pymc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "\n",
    "def fit_2pl_pymc(response_matrix, n_samples=2000, tune=1000, chains=4):\n",
    "    \"\"\"\n",
    "    Fit 2PL IRT model using PyMC\n",
    "\n",
    "    Args:\n",
    "        response_matrix: [n_participants x n_items] binary response matrix\n",
    "        n_samples: Number of samples after tuning\n",
    "        tune: Number of tuning steps\n",
    "        chains: Number of MCMC chains\n",
    "    \"\"\"\n",
    "    n_participants, n_items = response_matrix.shape\n",
    "\n",
    "    with pm.Model() as irt_2pl:\n",
    "        # Using better parameterization for sampling efficiency\n",
    "        abilities = pm.Normal('abilities', \n",
    "                            mu=0, \n",
    "                            sigma=1, \n",
    "                            shape=n_participants)\n",
    "\n",
    "        # Non-centered parameterization for better sampling\n",
    "        discrimination_raw = pm.HalfNormal('discrimination_raw', \n",
    "                                         sigma=1, \n",
    "                                         shape=n_items)\n",
    "        discrimination_offset = pm.Normal('discrimination_offset', \n",
    "                                        mu=0, \n",
    "                                        sigma=1, \n",
    "                                        shape=n_items)\n",
    "        discriminations = pm.Deterministic('discriminations', \n",
    "                                         discrimination_raw * (1 + discrimination_offset))\n",
    "\n",
    "        difficulties = pm.Normal('difficulties', \n",
    "                               mu=0, \n",
    "                               sigma=2, \n",
    "                               shape=n_items)\n",
    "\n",
    "        # 2PL Model with better numerical stability\n",
    "        logit_p = pm.math.dot(abilities[:, None], \n",
    "                             discriminations[None, :]) - \\\n",
    "                  (discriminations[None, :] * difficulties[None, :])\n",
    "\n",
    "        # Likelihood with potential for missing data handling\n",
    "        responses = pm.Bernoulli('responses', \n",
    "                                logit_p=logit_p, \n",
    "                                observed=response_matrix,\n",
    "                                shape=response_matrix.shape)\n",
    "\n",
    "        # Use modern NUTS sampler with better defaults\n",
    "        trace = pm.sample(n_samples, \n",
    "                         tune=tune, \n",
    "                         chains=chains, \n",
    "                         return_inferencedata=True,\n",
    "                         cores=1,\n",
    "                         target_accept=0.9)  # Slightly higher acceptance rate\n",
    "\n",
    "    return trace\n",
    "\n",
    "# Modern diagnostics using ArviZ\n",
    "def check_model_diagnostics(trace):\n",
    "    \"\"\"Comprehensive model diagnostics\"\"\"\n",
    "    diagnostics = {\n",
    "        'r_hat': az.rhat(trace),\n",
    "        'ess': az.ess(trace),\n",
    "        'mcse': az.mcse(trace),\n",
    "        'divergences': az.summary(trace)['diverging'].sum()\n",
    "    }\n",
    "\n",
    "    # Check for convergence issues\n",
    "    has_issues = (\n",
    "        (diagnostics['r_hat'] > 1.01).any() or\n",
    "        (diagnostics['ess'] < 400).any() or\n",
    "        diagnostics['divergences'] > 0\n",
    "    )\n",
    "\n",
    "    if has_issues:\n",
    "        print(\"Warning: Potential convergence issues detected\")\n",
    "\n",
    "    return diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (4 chains in 1 job)\n",
      "NUTS: [abilities, discrimination_raw, discrimination_offset, difficulties]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db9c4fc9d064ae38944db318fb2d08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    trace = fit_2pl_pymc(results['binary_matrix'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check diagnostics\n",
    "diagnostics = check_model_diagnostics(trace)\n",
    "\n",
    "# Plot results\n",
    "az.plot_trace(trace)\n",
    "az.plot_posterior(trace)\n",
    "az.plot_forest(trace, var_names=['discriminations', 'difficulties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
